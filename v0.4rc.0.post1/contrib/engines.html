



<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ignite.contrib.engines &mdash; ignite master documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/ignite_logomark.svg"/>
  
  
  
    <link rel="canonical" href="https://pytorch.org/ignite/index.htmlcontrib/engines.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/css/ignite_theme.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@1.0.0-alpha.28/dist/style.min.css" type="text/css" />
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ignite.contrib.metrics" href="metrics.html" />
    <link rel="prev" title="ignite.utils" href="../utils.html" /> 

  <!-- katex links / this needs to be loaded before fonts.html -->

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css" crossorigin="anonymous">
<script async src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js" crossorigin="anonymous"></script>

<!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">

    <a class="header-logo" href="https://pytorch.org/ignite" aria-label="PyTorch"></a>

    <div class="header-container">

      <div class="main-menu">
        <ul>
          <li>
            <a href="../quickstart.html">Quickstart</a>
          </li>

          <li>
            <a href="../concepts.html">Concepts</a>
          </li>

          <li>
            <a href="../examples.html">Examples</a>
          </li>

          <li>
            <a href="../faq.html">FAQ</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite">Github</a>
          </li>

          <li>
            <a href="https://pytorch.org/ignite/master/about.html">About us</a> 
          </li>

        </ul>
      </div>

      <!-- <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a> -->
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  v0.4rc.0.post1
                </div>
              
            

            <div id="docsearch"></div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../engine.html">ignite.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../handlers.html">ignite.handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metrics.html">ignite.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.html">ignite.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exceptions.html">ignite.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">ignite.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">Contrib Package Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">ignite.contrib.engines</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">ignite.contrib.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="handlers.html">ignite.contrib.handlers</a></li>
</ul>
<p class="caption"><span class="caption-text">Team</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../governance.html">PyTorch-Ignite governance</a></li>
</ul>

            
          
        </div>
      </div>

      <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Other Versions</span>
        v: v0.4rc.0.post1
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>Tags</dt>
            <dd><a href="../../v0.1.0/index.html">v0.1.0</a></dd>
            <dd><a href="../../v0.1.1/contrib/engines.html">v0.1.1</a></dd>
            <dd><a href="../../v0.1.2/contrib/engines.html">v0.1.2</a></dd>
            <dd><a href="../../v0.2.0/contrib/engines.html">v0.2.0</a></dd>
            <dd><a href="../../v0.2.1/contrib/engines.html">v0.2.1</a></dd>
            <dd><a href="../../v0.3.0/contrib/engines.html">v0.3.0</a></dd>
            <dd><a href="../../v0.4.0.post1/contrib/engines.html">v0.4.0.post1</a></dd>
            <dd><a href="../../v0.4.1/contrib/engines.html">v0.4.1</a></dd>
            <dd><a href="../../v0.4.2/contrib/engines.html">v0.4.2</a></dd>
            <dd><a href="../../v0.4.3/contrib/engines.html">v0.4.3</a></dd>
            <dd><a href="../../v0.4.4.post1/contrib/engines.html">v0.4.4.post1</a></dd>
            <dd><a href="engines.html">v0.4rc.0.post1</a></dd>
        </dl>
        <dl>
            <dt>Branches</dt>
            <dd><a href="../../master/contrib/engines.html">master</a></dd>
        </dl>
    </div>
</div>

    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>ignite.contrib.engines</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/contrib/engines.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="ignite-contrib-engines">
<h1>ignite.contrib.engines<a class="headerlink" href="#ignite-contrib-engines" title="Permalink to this headline">¶</a></h1>
<p>Contribution module of engines and helper tools</p>
<div class="section" id="module-ignite.contrib.engines.tbptt">
<span id="truncated-backpropagation-throught-time"></span><h2>Truncated Backpropagation Throught Time<a class="headerlink" href="#module-ignite.contrib.engines.tbptt" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="ignite.contrib.engines.tbptt.Tbptt_Events">
<em class="property">class </em><code class="sig-prename descclassname">ignite.contrib.engines.tbptt.</code><code class="sig-name descname">Tbptt_Events</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/engines/tbptt.html#Tbptt_Events"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.engines.tbptt.Tbptt_Events" title="Permalink to this definition">¶</a></dt>
<dd><p>Aditional tbptt events.</p>
<p>Additional events for truncated backpropagation throught time dedicated
trainer.</p>
</dd></dl>

<dl class="py function">
<dt id="ignite.contrib.engines.tbptt.create_supervised_tbptt_trainer">
<code class="sig-prename descclassname">ignite.contrib.engines.tbptt.</code><code class="sig-name descname">create_supervised_tbptt_trainer</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">optimizer</em>, <em class="sig-param">loss_fn</em>, <em class="sig-param">tbtt_step</em>, <em class="sig-param">dim=0</em>, <em class="sig-param">device=None</em>, <em class="sig-param">non_blocking=False</em>, <em class="sig-param">prepare_batch=&lt;function _prepare_batch&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/engines/tbptt.html#create_supervised_tbptt_trainer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.engines.tbptt.create_supervised_tbptt_trainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a trainer for truncated backprop through time supervised models.</p>
<p>Training recurrent model on long sequences is computationally intensive as
it requires to process the whole sequence before getting a gradient.
However, when the training loss is computed over many outputs
(<a class="reference external" href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">X to many</a>),
there is an opportunity to compute a gradient over a subsequence. This is
known as
<a class="reference external" href="https://machinelearningmastery.com/gentle-introduction-backpropagation-time/">truncated backpropagation through time</a>.
This supervised trainer apply gradient optimization step every <cite>tbtt_step</cite>
time steps of the sequence, while backpropagating through the same
<cite>tbtt_step</cite> time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<cite>torch.nn.Module</cite>) – the model to train.</p></li>
<li><p><strong>optimizer</strong> (<cite>torch.optim.Optimizer</cite>) – the optimizer to use.</p></li>
<li><p><strong>loss_fn</strong> (<em>torch.nn loss function</em>) – the loss function to use.</p></li>
<li><p><strong>tbtt_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – the length of time chunks (last one may be smaller).</p></li>
<li><p><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – axis representing the time dimension.</p></li>
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) – device type specification (default: None).
Applies to batches.</p></li>
<li><p><strong>non_blocking</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True and this copy is between CPU and GPU,
the copy may occur asynchronously with respect to the host. For other cases,
this argument has no effect.</p></li>
<li><p><strong>prepare_batch</strong> (<em>callable</em><em>, </em><em>optional</em>) – function that receives <cite>batch</cite>, <cite>device</cite>,
<cite>non_blocking</cite> and outputs tuple of tensors <cite>(batch_x, batch_y)</cite>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The internal use of <cite>device</cite> has changed.
<cite>device</cite> will now <em>only</em> be used to move the input data to the correct device.
The <cite>model</cite> should be moved by the user before creating an optimizer.</p>
<p>For more information see:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/optim.html#constructing-it">PyTorch Documentation</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/pytorch/issues/7844#issuecomment-503713840">PyTorch’s Explanation</a></p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a trainer engine with supervised update function.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine">Engine</a></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite.contrib.engines.common">
<span id="helper-methods-to-setup-trainer-evaluator"></span><h2>Helper methods to setup trainer/evaluator<a class="headerlink" href="#module-ignite.contrib.engines.common" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="ignite.contrib.engines.common.add_early_stopping_by_val_score">
<code class="sig-prename descclassname">ignite.contrib.engines.common.</code><code class="sig-name descname">add_early_stopping_by_val_score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">patience</span></em>, <em class="sig-param"><span class="n">evaluator</span></em>, <em class="sig-param"><span class="n">trainer</span></em>, <em class="sig-param"><span class="n">metric_name</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/engines/common.html#add_early_stopping_by_val_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.engines.common.add_early_stopping_by_val_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Method setups early stopping handler based on the score (named by <cite>metric_name</cite>) provided by <cite>evaluator</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patience</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – number of events to wait if no improvement and then stop the training.</p></li>
<li><p><strong>evaluator</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a>) – evaluation engine used to provide the score</p></li>
<li><p><strong>trainer</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a>) – trainer engine to stop the run if no improvement.</p></li>
<li><p><strong>metric_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – metric name to use for score evaluation. This metric should be present in
<cite>evaluator.state.metrics</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">EarlyStopping</span></code> handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ignite.contrib.engines.common.save_best_model_by_val_score">
<code class="sig-prename descclassname">ignite.contrib.engines.common.</code><code class="sig-name descname">save_best_model_by_val_score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output_path</span></em>, <em class="sig-param"><span class="n">evaluator</span></em>, <em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">metric_name</span></em>, <em class="sig-param"><span class="n">n_saved</span><span class="o">=</span><span class="default_value">3</span></em>, <em class="sig-param"><span class="n">trainer</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tag</span><span class="o">=</span><span class="default_value">'val'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/engines/common.html#save_best_model_by_val_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.engines.common.save_best_model_by_val_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Method adds a handler to <cite>evaluator</cite> to save best models based on the score (named by <cite>metric_name</cite>)
provided by <cite>evaluator</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – output path to indicate where to save best models</p></li>
<li><p><strong>evaluator</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a>) – evaluation engine used to provide the score</p></li>
<li><p><strong>model</strong> (<em>nn.Module</em>) – model to store</p></li>
<li><p><strong>metric_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – metric name to use for score evaluation. This metric should be present in
<cite>evaluator.state.metrics</cite>.</p></li>
<li><p><strong>n_saved</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – number of best models to store</p></li>
<li><p><strong>trainer</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a><em>, </em><em>optional</em>) – trainer engine to fetch the epoch when saving the best model.</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) – score name prefix: <cite>{tag}_{metric_name}</cite>. By default, tag is “val”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">Checkpoint</span></code> handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ignite.contrib.engines.common.setup_common_distrib_training_handlers">
<code class="sig-prename descclassname">ignite.contrib.engines.common.</code><code class="sig-name descname">setup_common_distrib_training_handlers</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">trainer</span></em>, <em class="sig-param"><span class="n">train_sampler</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">to_save</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save_every_iters</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">output_path</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">lr_scheduler</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">with_gpu_stats</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">output_names</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">with_pbars</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">with_pbar_on_iters</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">log_every_iters</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">device</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">stop_on_nan</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">clear_cuda_cache</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.engines.common.setup_common_distrib_training_handlers" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Helper method to setup trainer with common handlers (it also supports distributed configuration):</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="../handlers.html#ignite.handlers.TerminateOnNan" title="ignite.handlers.TerminateOnNan"><code class="xref py py-class docutils literal notranslate"><span class="pre">TerminateOnNan</span></code></a></p></li>
<li><p>handler to setup learning rate scheduling</p></li>
<li><p><a class="reference internal" href="../handlers.html#ignite.handlers.ModelCheckpoint" title="ignite.handlers.ModelCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code></a></p></li>
<li><p><a class="reference internal" href="../metrics.html#ignite.metrics.RunningAverage" title="ignite.metrics.RunningAverage"><code class="xref py py-class docutils literal notranslate"><span class="pre">RunningAverage</span></code></a> on <cite>update_function</cite> output</p></li>
<li><p>Two progress bars on epochs and optionally on iterations</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a>) – trainer engine. Output of trainer’s <cite>update_function</cite> should be a dictionary
or sequence or a single tensor.</p></li>
<li><p><strong>train_sampler</strong> (<em>torch.utils.data.DistributedSampler</em><em>, </em><em>optional</em>) – Optional distributed sampler used to call
<cite>set_epoch</cite> method on epoch started event.</p></li>
<li><p><strong>to_save</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a><em>, </em><em>optional</em>) – dictionary with objects to save in the checkpoint. This argument is passed to
<a class="reference internal" href="../handlers.html#ignite.handlers.Checkpoint" title="ignite.handlers.Checkpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Checkpoint</span></code></a> instance.</p></li>
<li><p><strong>save_every_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – saving interval. By default, <cite>to_save</cite> objects are stored
each 1000 iterations.</p></li>
<li><p><strong>output_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) – output path to indicate where <cite>to_save</cite> objects are stored.</p></li>
<li><p><strong>lr_scheduler</strong> (ParamScheduler or subclass of <cite>torch.optim.lr_scheduler._LRScheduler</cite>) – learning rate scheduler
as native torch LRScheduler or ignite’s parameter scheduler.</p></li>
<li><p><strong>with_gpu_stats</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, <code class="xref py py-class docutils literal notranslate"><span class="pre">GpuInfo</span></code> is attached to the
trainer. This requires <cite>pynvml</cite> package to be installed.</p></li>
<li><p><strong>output_names</strong> (<em>list/tuple</em><em>, </em><em>optional</em>) – list of names associated with <cite>update_function</cite> output dictionary.</p></li>
<li><p><strong>with_pbars</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, two progress bars on epochs and optionally on iterations are attached.
Default, True.</p></li>
<li><p><strong>with_pbar_on_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, a progress bar on iterations is attached to the trainer.
Default, True.</p></li>
<li><p><strong>log_every_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – logging interval for <code class="xref py py-class docutils literal notranslate"><span class="pre">GpuInfo</span></code> and for
epoch-wise progress bar. Default, 100.</p></li>
<li><p><strong>stop_on_nan</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, <a class="reference internal" href="../handlers.html#ignite.handlers.TerminateOnNan" title="ignite.handlers.TerminateOnNan"><code class="xref py py-class docutils literal notranslate"><span class="pre">TerminateOnNan</span></code></a> handler is added to the trainer.
Default, True.</p></li>
<li><p><strong>clear_cuda_cache</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, <cite>torch.cuda.empty_cache()</cite> is called every end of epoch.
Default, True.</p></li>
<li><p><strong>device</strong> (<em>str of torch.device</em><em>, </em><em>optional</em>) – deprecated argument, it will be removed in v0.5.0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ignite.contrib.engines.common.setup_common_training_handlers">
<code class="sig-prename descclassname">ignite.contrib.engines.common.</code><code class="sig-name descname">setup_common_training_handlers</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">trainer</span></em>, <em class="sig-param"><span class="n">train_sampler</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">to_save</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save_every_iters</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">output_path</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">lr_scheduler</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">with_gpu_stats</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">output_names</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">with_pbars</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">with_pbar_on_iters</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">log_every_iters</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">device</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">stop_on_nan</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">clear_cuda_cache</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/engines/common.html#setup_common_training_handlers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.engines.common.setup_common_training_handlers" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Helper method to setup trainer with common handlers (it also supports distributed configuration):</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="../handlers.html#ignite.handlers.TerminateOnNan" title="ignite.handlers.TerminateOnNan"><code class="xref py py-class docutils literal notranslate"><span class="pre">TerminateOnNan</span></code></a></p></li>
<li><p>handler to setup learning rate scheduling</p></li>
<li><p><a class="reference internal" href="../handlers.html#ignite.handlers.ModelCheckpoint" title="ignite.handlers.ModelCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code></a></p></li>
<li><p><a class="reference internal" href="../metrics.html#ignite.metrics.RunningAverage" title="ignite.metrics.RunningAverage"><code class="xref py py-class docutils literal notranslate"><span class="pre">RunningAverage</span></code></a> on <cite>update_function</cite> output</p></li>
<li><p>Two progress bars on epochs and optionally on iterations</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a>) – trainer engine. Output of trainer’s <cite>update_function</cite> should be a dictionary
or sequence or a single tensor.</p></li>
<li><p><strong>train_sampler</strong> (<em>torch.utils.data.DistributedSampler</em><em>, </em><em>optional</em>) – Optional distributed sampler used to call
<cite>set_epoch</cite> method on epoch started event.</p></li>
<li><p><strong>to_save</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a><em>, </em><em>optional</em>) – dictionary with objects to save in the checkpoint. This argument is passed to
<a class="reference internal" href="../handlers.html#ignite.handlers.Checkpoint" title="ignite.handlers.Checkpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Checkpoint</span></code></a> instance.</p></li>
<li><p><strong>save_every_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – saving interval. By default, <cite>to_save</cite> objects are stored
each 1000 iterations.</p></li>
<li><p><strong>output_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) – output path to indicate where <cite>to_save</cite> objects are stored.</p></li>
<li><p><strong>lr_scheduler</strong> (ParamScheduler or subclass of <cite>torch.optim.lr_scheduler._LRScheduler</cite>) – learning rate scheduler
as native torch LRScheduler or ignite’s parameter scheduler.</p></li>
<li><p><strong>with_gpu_stats</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, <code class="xref py py-class docutils literal notranslate"><span class="pre">GpuInfo</span></code> is attached to the
trainer. This requires <cite>pynvml</cite> package to be installed.</p></li>
<li><p><strong>output_names</strong> (<em>list/tuple</em><em>, </em><em>optional</em>) – list of names associated with <cite>update_function</cite> output dictionary.</p></li>
<li><p><strong>with_pbars</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, two progress bars on epochs and optionally on iterations are attached.
Default, True.</p></li>
<li><p><strong>with_pbar_on_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, a progress bar on iterations is attached to the trainer.
Default, True.</p></li>
<li><p><strong>log_every_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – logging interval for <code class="xref py py-class docutils literal notranslate"><span class="pre">GpuInfo</span></code> and for
epoch-wise progress bar. Default, 100.</p></li>
<li><p><strong>stop_on_nan</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, <a class="reference internal" href="../handlers.html#ignite.handlers.TerminateOnNan" title="ignite.handlers.TerminateOnNan"><code class="xref py py-class docutils literal notranslate"><span class="pre">TerminateOnNan</span></code></a> handler is added to the trainer.
Default, True.</p></li>
<li><p><strong>clear_cuda_cache</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, <cite>torch.cuda.empty_cache()</cite> is called every end of epoch.
Default, True.</p></li>
<li><p><strong>device</strong> (<em>str of torch.device</em><em>, </em><em>optional</em>) – deprecated argument, it will be removed in v0.5.0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ignite.contrib.engines.common.setup_mlflow_logging">
<code class="sig-prename descclassname">ignite.contrib.engines.common.</code><code class="sig-name descname">setup_mlflow_logging</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">trainer</span></em>, <em class="sig-param"><span class="n">optimizers</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">evaluators</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_every_iters</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/engines/common.html#setup_mlflow_logging"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.engines.common.setup_mlflow_logging" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Method to setup MLflow logging on trainer and a list of evaluators. Logged metrics are:</dt><dd><ul class="simple">
<li><p>Training metrics, e.g. running average loss values</p></li>
<li><p>Learning rate(s)</p></li>
<li><p>Evaluation metrics</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a>) – trainer engine</p></li>
<li><p><strong>optimizers</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v1.8.0)"><em>torch.optim.Optimizer</em></a><em> or </em><em>dict of torch.optim.Optimizer</em><em>, </em><em>optional</em>) – single or dictionary of
torch optimizers. If a dictionary, keys are used as tags arguments for logging.</p></li>
<li><p><strong>evaluators</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a><em> or </em><em>dict of Engine</em><em>, </em><em>optional</em>) – single or dictionary of evaluators. If a dictionary,
keys are used as tags arguments for logging.</p></li>
<li><p><strong>log_every_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – interval for loggers attached to iteration events. To log every iteration,
value can be set to 1 or None.</p></li>
<li><p><strong>**kwargs</strong> – optional keyword args to be passed to construct the logger.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>MLflowLogger</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ignite.contrib.engines.common.setup_neptune_logging">
<code class="sig-prename descclassname">ignite.contrib.engines.common.</code><code class="sig-name descname">setup_neptune_logging</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">trainer</span></em>, <em class="sig-param"><span class="n">optimizers</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">evaluators</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_every_iters</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/engines/common.html#setup_neptune_logging"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.engines.common.setup_neptune_logging" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Method to setup Neptune logging on trainer and a list of evaluators. Logged metrics are:</dt><dd><ul class="simple">
<li><p>Training metrics, e.g. running average loss values</p></li>
<li><p>Learning rate(s)</p></li>
<li><p>Evaluation metrics</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a>) – trainer engine</p></li>
<li><p><strong>optimizers</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v1.8.0)"><em>torch.optim.Optimizer</em></a><em> or </em><em>dict of torch.optim.Optimizer</em><em>, </em><em>optional</em>) – single or dictionary of
torch optimizers. If a dictionary, keys are used as tags arguments for logging.</p></li>
<li><p><strong>evaluators</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a><em> or </em><em>dict of Engine</em><em>, </em><em>optional</em>) – single or dictionary of evaluators. If a dictionary,
keys are used as tags arguments for logging.</p></li>
<li><p><strong>log_every_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – interval for loggers attached to iteration events. To log every iteration,
value can be set to 1 or None.</p></li>
<li><p><strong>**kwargs</strong> – optional keyword args to be passed to construct the logger.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>NeptuneLogger</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ignite.contrib.engines.common.setup_plx_logging">
<code class="sig-prename descclassname">ignite.contrib.engines.common.</code><code class="sig-name descname">setup_plx_logging</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">trainer</span></em>, <em class="sig-param"><span class="n">optimizers</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">evaluators</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_every_iters</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/engines/common.html#setup_plx_logging"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.engines.common.setup_plx_logging" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Method to setup Polyaxon logging on trainer and a list of evaluators. Logged metrics are:</dt><dd><ul class="simple">
<li><p>Training metrics, e.g. running average loss values</p></li>
<li><p>Learning rate(s)</p></li>
<li><p>Evaluation metrics</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a>) – trainer engine</p></li>
<li><p><strong>optimizers</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v1.8.0)"><em>torch.optim.Optimizer</em></a><em> or </em><em>dict of torch.optim.Optimizer</em><em>, </em><em>optional</em>) – single or dictionary of
torch optimizers. If a dictionary, keys are used as tags arguments for logging.</p></li>
<li><p><strong>evaluators</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a><em> or </em><em>dict of Engine</em><em>, </em><em>optional</em>) – single or dictionary of evaluators. If a dictionary,
keys are used as tags arguments for logging.</p></li>
<li><p><strong>log_every_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – interval for loggers attached to iteration events. To log every iteration,
value can be set to 1 or None.</p></li>
<li><p><strong>**kwargs</strong> – optional keyword args to be passed to construct the logger.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>PolyaxonLogger</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ignite.contrib.engines.common.setup_tb_logging">
<code class="sig-prename descclassname">ignite.contrib.engines.common.</code><code class="sig-name descname">setup_tb_logging</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output_path</span></em>, <em class="sig-param"><span class="n">trainer</span></em>, <em class="sig-param"><span class="n">optimizers</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">evaluators</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_every_iters</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/engines/common.html#setup_tb_logging"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.engines.common.setup_tb_logging" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Method to setup TensorBoard logging on trainer and a list of evaluators. Logged metrics are:</dt><dd><ul class="simple">
<li><p>Training metrics, e.g. running average loss values</p></li>
<li><p>Learning rate(s)</p></li>
<li><p>Evaluation metrics</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – logging directory path</p></li>
<li><p><strong>trainer</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a>) – trainer engine</p></li>
<li><p><strong>optimizers</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v1.8.0)"><em>torch.optim.Optimizer</em></a><em> or </em><em>dict of torch.optim.Optimizer</em><em>, </em><em>optional</em>) – single or dictionary of
torch optimizers. If a dictionary, keys are used as tags arguments for logging.</p></li>
<li><p><strong>evaluators</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a><em> or </em><em>dict of Engine</em><em>, </em><em>optional</em>) – single or dictionary of evaluators. If a dictionary,
keys are used as tags arguments for logging.</p></li>
<li><p><strong>log_every_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – interval for loggers attached to iteration events. To log every iteration,
value can be set to 1 or None.</p></li>
<li><p><strong>**kwargs</strong> – optional keyword args to be passed to construct the logger.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>TensorboardLogger</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ignite.contrib.engines.common.setup_trains_logging">
<code class="sig-prename descclassname">ignite.contrib.engines.common.</code><code class="sig-name descname">setup_trains_logging</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">trainer</span></em>, <em class="sig-param"><span class="n">optimizers</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">evaluators</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_every_iters</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/engines/common.html#setup_trains_logging"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.engines.common.setup_trains_logging" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Method to setup Trains logging on trainer and a list of evaluators. Logged metrics are:</dt><dd><ul class="simple">
<li><p>Training metrics, e.g. running average loss values</p></li>
<li><p>Learning rate(s)</p></li>
<li><p>Evaluation metrics</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a>) – trainer engine</p></li>
<li><p><strong>optimizers</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v1.8.0)"><em>torch.optim.Optimizer</em></a><em> or </em><em>dict of torch.optim.Optimizer</em><em>, </em><em>optional</em>) – single or dictionary of
torch optimizers. If a dictionary, keys are used as tags arguments for logging.</p></li>
<li><p><strong>evaluators</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a><em> or </em><em>dict of Engine</em><em>, </em><em>optional</em>) – single or dictionary of evaluators. If a dictionary,
keys are used as tags arguments for logging.</p></li>
<li><p><strong>log_every_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – interval for loggers attached to iteration events. To log every iteration,
value can be set to 1 or None.</p></li>
<li><p><strong>**kwargs</strong> – optional keyword args to be passed to construct the logger.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>TrainsLogger</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ignite.contrib.engines.common.setup_visdom_logging">
<code class="sig-prename descclassname">ignite.contrib.engines.common.</code><code class="sig-name descname">setup_visdom_logging</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">trainer</span></em>, <em class="sig-param"><span class="n">optimizers</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">evaluators</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_every_iters</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/engines/common.html#setup_visdom_logging"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.engines.common.setup_visdom_logging" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Method to setup Visdom logging on trainer and a list of evaluators. Logged metrics are:</dt><dd><ul class="simple">
<li><p>Training metrics, e.g. running average loss values</p></li>
<li><p>Learning rate(s)</p></li>
<li><p>Evaluation metrics</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a>) – trainer engine</p></li>
<li><p><strong>optimizers</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v1.8.0)"><em>torch.optim.Optimizer</em></a><em> or </em><em>dict of torch.optim.Optimizer</em><em>, </em><em>optional</em>) – single or dictionary of
torch optimizers. If a dictionary, keys are used as tags arguments for logging.</p></li>
<li><p><strong>evaluators</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a><em> or </em><em>dict of Engine</em><em>, </em><em>optional</em>) – single or dictionary of evaluators. If a dictionary,
keys are used as tags arguments for logging.</p></li>
<li><p><strong>log_every_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – interval for loggers attached to iteration events. To log every iteration,
value can be set to 1 or None.</p></li>
<li><p><strong>**kwargs</strong> – optional keyword args to be passed to construct the logger.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>VisdomLogger</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ignite.contrib.engines.common.setup_wandb_logging">
<code class="sig-prename descclassname">ignite.contrib.engines.common.</code><code class="sig-name descname">setup_wandb_logging</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">trainer</span></em>, <em class="sig-param"><span class="n">optimizers</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">evaluators</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_every_iters</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/engines/common.html#setup_wandb_logging"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.engines.common.setup_wandb_logging" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Method to setup WandB logging on trainer and a list of evaluators. Logged metrics are:</dt><dd><ul class="simple">
<li><p>Training metrics, e.g. running average loss values</p></li>
<li><p>Learning rate(s)</p></li>
<li><p>Evaluation metrics</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a>) – trainer engine</p></li>
<li><p><strong>optimizers</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v1.8.0)"><em>torch.optim.Optimizer</em></a><em> or </em><em>dict of torch.optim.Optimizer</em><em>, </em><em>optional</em>) – single or dictionary of
torch optimizers. If a dictionary, keys are used as tags arguments for logging.</p></li>
<li><p><strong>evaluators</strong> (<a class="reference internal" href="../engine.html#id0" title="ignite.engine.engine.Engine"><em>Engine</em></a><em> or </em><em>dict of Engine</em><em>, </em><em>optional</em>) – single or dictionary of evaluators. If a dictionary,
keys are used as tags arguments for logging.</p></li>
<li><p><strong>log_every_iters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – interval for loggers attached to iteration events. To log every iteration,
value can be set to 1 or None.</p></li>
<li><p><strong>**kwargs</strong> – optional keyword args to be passed to construct the logger.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>WandBLogger</p>
</dd>
</dl>
</dd></dl>

</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="metrics.html" class="btn btn-neutral float-right" title="ignite.contrib.metrics" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="../utils.html" class="btn btn-neutral" title="ignite.utils" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <table>
      <tr>
        <td>
            <p>
                &copy; Copyright 2021, PyTorch-Ignite Contributors.
            </p>
            
              <div>
                Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
              </div>
          
        </td>
        <td>
            
              <div>
                <a href="https://www.netlify.com"><img src="https://www.netlify.com/img/global/badges/netlify-light.svg" alt="Deploys by Netlify" /></a>
              </div>
            
        </td>
      </tr>
    </table>
  </div> 

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">ignite.contrib.engines</a><ul>
<li><a class="reference internal" href="#module-ignite.contrib.engines.tbptt">Truncated Backpropagation Throught Time</a></li>
<li><a class="reference internal" href="#module-ignite.contrib.engines.common">Helper methods to setup trainer/evaluator</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <!-- commented out for Ignite -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <!-- <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/ignite/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="">View Resources</a>
        </div>
      </div>
    </div> -->
  </div>

  <!-- <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/ignite" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/ignite">PyTorch</a></li>
            <li><a href="">Get Started</a></li>
            <li><a href="">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="">Blog</a></li>
            <li><a href="">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="">Support</a></li>
            <li><a href="">Tutorials</a></li>
            <li><a href="https://pytorch.org/ignite/index.html">Docs</a></li>
            <li><a href="" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/ignite/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/ignite/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!~~ real people should not fill this in and expect good things - do not remove this or risk form bot signups ~~>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer> -->


  <!-- end of commented out for Ignite -->

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->
  <!--
  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/ignite" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="">Blog</a>
          </li>

          <li>
            <a href="">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/ignite/index.html">Docs</a>
          </li>

          <li>
            <a href="">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  -->
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    var collapsedSections = ['Notes']
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@docsearch/js@1.0.0-alpha.28/dist/umd/index.min.js"></script>
  <script type="text/javascript">
  let VERSION
  if ('v0.4rc.0.post1'.includes('v')) {
    VERSION = 'v0.4rc.0.post1'
  } else {
    VERSION = 'master'
  }
  docsearch({
    container: '#docsearch',
    apiKey: '19a7a7a75d87608d6f42c722ed1e293f',
    indexName: 'ignite',
    placeholder: 'Search PyTorch-Ignite docs',
    searchParameters: {
      'facetFilters': [`version:${VERSION}`],
    }
  });
  </script>
</body>
</html>